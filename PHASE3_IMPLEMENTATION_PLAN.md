# Phase 3 Implementation Plan: Threshold Calibration Dashboard

**Status:** üìã **PLANNING COMPLETE - READY FOR IMPLEMENTATION**
**Timeline:** 2 weeks (December 1-14, 2025)
**Dependencies:** Phase 1 ‚úÖ + Phase 2 ‚úÖ (30+ days of drift data)
**Team:** ML Engineering + Frontend/Backend Engineering
**Complexity:** üü° **MEDIUM** (UI components + simulation logic)

---

## Executive Summary

### Objective

Build **operator-friendly threshold management system** with visual impact simulation, enabling NOC operators to tune anomaly detection and drift thresholds without code changes, reducing threshold adjustment time from hours to minutes.

### Problem Statement

**Current State**:
- ‚ùå Threshold changes require code modifications
- ‚ùå No visualization of threshold impact
- ‚ùå No audit trail for threshold adjustments
- ‚ùå Operators can't tune thresholds independently

**Desired State**:
- ‚úÖ Web UI for threshold management
- ‚úÖ Real-time impact simulation (historical replay)
- ‚úÖ Complete audit trail (who/when/why)
- ‚úÖ One-click rollback to previous thresholds

### Components to Build

1. **ThresholdAuditLog Model** - Track all threshold changes
2. **ThresholdSimulatorService** - Historical replay for impact analysis
3. **Django Admin Extensions** - Enhanced BaselineProfile threshold management
4. **API Endpoints** (4) - Threshold CRUD + simulation
5. **Threshold Management UI** - Interactive calibration interface (if React/Vue exists)
6. **Comprehensive Tests** - Unit + integration tests
7. **Operator Documentation** - Threshold tuning guide

### Expected Impact

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Threshold Adjustment Time | 2-4 hours | 2-5 minutes | **-98%** |
| Code Deployment Required | Yes | No | **Eliminated** |
| Impact Analysis | Manual calculation | Automated simulation | **Instant** |
| Rollback Time | 1-2 hours | < 1 minute | **-99%** |
| Operator Independence | Low | High | **Self-service** |

---

## Architecture Overview

### System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PHASE 3: THRESHOLD CALIBRATION                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   THRESHOLD SOURCES      ‚îÇ
‚îÇ                          ‚îÇ
‚îÇ  ‚Ä¢ BaselineProfile       ‚îÇ‚îÄ‚îÄ‚îê
‚îÇ    (dynamic_threshold)   ‚îÇ  ‚îÇ
‚îÇ  ‚Ä¢ FraudDetectionModel   ‚îÇ  ‚îÇ
‚îÇ    (optimal_threshold)   ‚îÇ  ‚îÇ
‚îÇ  ‚Ä¢ ML_CONFIG             ‚îÇ  ‚îÇ
‚îÇ    (drift thresholds)    ‚îÇ  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                              ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   DJANGO ADMIN INTERFACE          ‚îÇ
            ‚îÇ   (Enhanced BaselineProfile)      ‚îÇ
            ‚îÇ                                   ‚îÇ
            ‚îÇ  ‚Ä¢ Inline threshold editing       ‚îÇ
            ‚îÇ  ‚Ä¢ Visual z-score distribution    ‚îÇ
            ‚îÇ  ‚Ä¢ Batch update capability        ‚îÇ
            ‚îÇ  ‚Ä¢ Impact preview                 ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   API LAYER                    ‚îÇ
            ‚îÇ   (RESTful Endpoints)          ‚îÇ
            ‚îÇ                                ‚îÇ
            ‚îÇ  GET  /api/v2/thresholds/      ‚îÇ
            ‚îÇ  PATCH /api/v2/thresholds/{id}/‚îÇ
            ‚îÇ  POST  /api/v2/thresholds/simulate/‚îÇ
            ‚îÇ  POST  /api/v2/thresholds/reset/‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   ThresholdSimulatorService      ‚îÇ
            ‚îÇ   (Impact Analysis)              ‚îÇ
            ‚îÇ                                  ‚îÇ
            ‚îÇ  ‚Ä¢ Historical replay (30 days)   ‚îÇ
            ‚îÇ  ‚Ä¢ Calculate projected metrics:  ‚îÇ
            ‚îÇ    - Alert count                 ‚îÇ
            ‚îÇ    - False positive rate         ‚îÇ
            ‚îÇ    - True positive rate          ‚îÇ
            ‚îÇ    - Automation rate             ‚îÇ
            ‚îÇ  ‚Ä¢ Generate recommendation       ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Threshold Update Logic         ‚îÇ
            ‚îÇ   (Database Transactions)        ‚îÇ
            ‚îÇ                                  ‚îÇ
            ‚îÇ  1. Validate new threshold       ‚îÇ
            ‚îÇ  2. Create audit log entry       ‚îÇ
            ‚îÇ  3. Update BaselineProfile       ‚îÇ
            ‚îÇ  4. Broadcast change (WebSocket) ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   ThresholdAuditLog              ‚îÇ
            ‚îÇ   (Change History)               ‚îÇ
            ‚îÇ                                  ‚îÇ
            ‚îÇ  ‚Ä¢ Who changed (user)            ‚îÇ
            ‚îÇ  ‚Ä¢ When changed (timestamp)      ‚îÇ
            ‚îÇ  ‚Ä¢ Old value ‚Üí New value         ‚îÇ
            ‚îÇ  ‚Ä¢ Reason (free text)            ‚îÇ
            ‚îÇ  ‚Ä¢ Impact metrics (projected)    ‚îÇ
            ‚îÇ  ‚Ä¢ Rollback reference            ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Detailed Component Specifications

### Component 1: ThresholdAuditLog Model

**File**: `apps/noc/security_intelligence/models/threshold_audit_log.py` (NEW)

**Purpose**: Track all threshold changes for audit and rollback

**Schema**:
```python
class ThresholdAuditLog(BaseModel, TenantAwareModel):
    """
    Audit log for threshold calibration changes.

    Tracks who changed what threshold, when, why, and the impact.
    Enables rollback to previous thresholds.
    """

    # What was changed
    baseline_profile = models.ForeignKey(
        'BaselineProfile',
        on_delete=models.CASCADE,
        related_name='threshold_changes',
        help_text='Baseline profile that was modified'
    )

    threshold_type = models.CharField(
        max_length=50,
        choices=[
            ('dynamic_threshold', 'Z-Score Dynamic Threshold'),
            ('false_positive_rate', 'False Positive Rate Target'),
            ('sensitivity_override', 'Manual Sensitivity Override'),
        ],
        help_text='Type of threshold adjusted'
    )

    # Change details
    old_value = models.FloatField(help_text='Previous threshold value')
    new_value = models.FloatField(help_text='New threshold value')
    delta = models.FloatField(help_text='Change amount (new - old)')

    # Who and why
    changed_by = models.ForeignKey(
        settings.AUTH_USER_MODEL,
        on_delete=models.SET_NULL,
        null=True,
        help_text='User who made the change'
    )

    change_reason = models.TextField(
        blank=True,
        help_text='Reason for threshold adjustment'
    )

    # Impact analysis (from simulation)
    simulated_alert_count_before = models.IntegerField(
        null=True,
        help_text='Projected alerts with old threshold (30d simulation)'
    )
    simulated_alert_count_after = models.IntegerField(
        null=True,
        help_text='Projected alerts with new threshold (30d simulation)'
    )
    simulated_fp_rate_before = models.FloatField(
        null=True,
        help_text='Projected false positive rate (before)'
    )
    simulated_fp_rate_after = models.FloatField(
        null=True,
        help_text='Projected false positive rate (after)'
    )

    # Rollback support
    rolled_back = models.BooleanField(
        default=False,
        help_text='True if this change was rolled back'
    )
    rolled_back_at = models.DateTimeField(
        null=True,
        blank=True,
        help_text='When rollback occurred'
    )
    rolled_back_by = models.ForeignKey(
        settings.AUTH_USER_MODEL,
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='threshold_rollbacks',
        help_text='User who performed rollback'
    )

    class Meta:
        db_table = 'noc_threshold_audit_log'
        ordering = ['-created_at']
        indexes = [
            models.Index(fields=['baseline_profile', '-created_at']),
            models.Index(fields=['changed_by', '-created_at']),
            models.Index(fields=['rolled_back']),
        ]
```

**Lines**: ~85 (within Rule #7 limit)

---

### Component 2: ThresholdSimulatorService

**File**: `apps/noc/security_intelligence/services/threshold_simulator.py` (NEW)

**Purpose**: Simulate threshold impact using historical data

**Implementation**:
```python
"""
Threshold Simulator Service

Simulates impact of threshold changes using historical data replay.

Enables operators to:
- Preview threshold impact before applying
- Compare multiple threshold values
- Optimize for target false positive rate
- Understand trade-offs (alerts vs sensitivity)

Follows .claude/rules.md:
- Rule #7: Service < 150 lines
- Rule #8: Methods < 30 lines
"""

from typing import Dict, Any, List
from django.utils import timezone
from django.db.models import Avg, Count, Q
from datetime import timedelta
import numpy as np
import logging

logger = logging.getLogger('noc.threshold_simulator')


class ThresholdSimulatorService:
    """
    Simulate threshold impact using historical baseline data.

    Historical replay: Apply candidate threshold to last 30 days
    of anomaly detection data and calculate projected metrics.
    """

    @classmethod
    def simulate_threshold_impact(
        cls,
        baseline_profile,
        candidate_threshold: float,
        simulation_days: int = 30
    ) -> Dict[str, Any]:
        """
        Simulate impact of candidate threshold on historical data.

        Args:
            baseline_profile: BaselineProfile instance
            candidate_threshold: Proposed z-score threshold (e.g., 2.5)
            simulation_days: Days of history to replay (default 30)

        Returns:
            {
                'alert_count': int,  # Projected alerts with new threshold
                'false_positive_rate': float,
                'true_positive_rate': float,
                'precision': float,
                'recommendation': str,
                'comparison_to_current': dict
            }
        """
        from apps.noc.security_intelligence.models import AnomalyDetectionLog

        # Get historical anomaly data for this baseline
        cutoff = timezone.now() - timedelta(days=simulation_days)

        historical_data = AnomalyDetectionLog.objects.filter(
            baseline_profile=baseline_profile,
            detected_at__gte=cutoff
        ).values_list('z_score', 'was_true_positive')

        if len(historical_data) == 0:
            return {
                'status': 'insufficient_data',
                'reason': f'No historical data for last {simulation_days} days',
                'alert_count': 0
            }

        # Separate z-scores and ground truth
        z_scores = [z for z, _ in historical_data]
        actuals = [tp for _, tp in historical_data]

        # Apply candidate threshold
        projected_alerts = sum(1 for z in z_scores if abs(z) > candidate_threshold)

        # Calculate confusion matrix
        tp = sum(
            1 for z, actual in zip(z_scores, actuals)
            if abs(z) > candidate_threshold and actual
        )
        fp = sum(
            1 for z, actual in zip(z_scores, actuals)
            if abs(z) > candidate_threshold and not actual
        )
        tn = sum(
            1 for z, actual in zip(z_scores, actuals)
            if abs(z) <= candidate_threshold and not actual
        )
        fn = sum(
            1 for z, actual in zip(z_scores, actuals)
            if abs(z) <= candidate_threshold and actual
        )

        # Calculate metrics
        fp_rate = fp / (fp + tn) if (fp + tn) > 0 else 0
        tp_rate = tp / (tp + fn) if (tp + fn) > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0

        # Compare to current threshold
        current_threshold = baseline_profile.dynamic_threshold
        current_simulation = cls.simulate_threshold_impact(
            baseline_profile,
            current_threshold,
            simulation_days
        ) if current_threshold != candidate_threshold else None

        # Generate recommendation
        recommendation = cls._generate_recommendation(
            candidate_threshold,
            current_threshold,
            fp_rate,
            tp_rate,
            projected_alerts
        )

        result = {
            'status': 'success',
            'candidate_threshold': candidate_threshold,
            'simulation_days': simulation_days,
            'historical_samples': len(z_scores),

            # Projected metrics
            'alert_count': projected_alerts,
            'false_positive_rate': fp_rate,
            'true_positive_rate': tp_rate,
            'precision': precision,
            'confusion_matrix': {'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn},

            # Recommendation
            'recommendation': recommendation,

            # Comparison
            'comparison_to_current': current_simulation if current_simulation else {
                'alert_count_delta': 0,
                'fp_rate_delta': 0
            }
        }

        logger.info(
            f"Simulated threshold {candidate_threshold} for {baseline_profile}: "
            f"{projected_alerts} alerts, FP rate: {fp_rate:.2%}"
        )

        return result

    @staticmethod
    def _generate_recommendation(
        candidate: float,
        current: float,
        fp_rate: float,
        tp_rate: float,
        alert_count: int
    ) -> str:
        """Generate human-readable recommendation."""

        if fp_rate > 0.30:
            return (
                f"HIGH FALSE POSITIVE RATE ({fp_rate:.1%}). "
                f"Consider increasing threshold to reduce false alerts."
            )

        if fp_rate < 0.05 and tp_rate < 0.70:
            return (
                f"LOW SENSITIVITY (TP rate: {tp_rate:.1%}). "
                f"Consider decreasing threshold to catch more anomalies."
            )

        if 0.10 <= fp_rate <= 0.20 and tp_rate >= 0.75:
            return (
                f"OPTIMAL BALANCE: FP rate {fp_rate:.1%}, TP rate {tp_rate:.1%}. "
                f"This threshold provides good anomaly detection with acceptable false positives."
            )

        delta = candidate - current
        if abs(delta) < 0.2:
            return "Minimal change from current threshold. Impact will be small."

        if delta > 0:
            return (
                f"Increasing threshold by {delta:.1f} will reduce alerts by ~{int((delta/current)*100)}% "
                f"but may miss some anomalies."
            )
        else:
            return (
                f"Decreasing threshold by {abs(delta):.1f} will increase alerts by ~{int((abs(delta)/current)*100)}% "
                f"with higher sensitivity."
            )

    @classmethod
    def find_optimal_threshold(
        cls,
        baseline_profile,
        target_fp_rate: float = 0.10,
        simulation_days: int = 30
    ) -> Dict[str, Any]:
        """
        Find optimal threshold for target false positive rate.

        Uses binary search to find threshold that achieves target FP rate.

        Args:
            baseline_profile: BaselineProfile instance
            target_fp_rate: Target false positive rate (default 10%)
            simulation_days: Days of historical data

        Returns:
            {'optimal_threshold': float, 'achieved_fp_rate': float, ...}
        """
        # Binary search for optimal threshold (1.5 to 5.0 range)
        low, high = 1.5, 5.0
        best_threshold = baseline_profile.dynamic_threshold
        best_fp_diff = float('inf')

        for _ in range(10):  # Max 10 iterations
            mid = (low + high) / 2

            simulation = cls.simulate_threshold_impact(
                baseline_profile,
                mid,
                simulation_days
            )

            if simulation['status'] != 'success':
                break

            fp_rate = simulation['false_positive_rate']
            fp_diff = abs(fp_rate - target_fp_rate)

            if fp_diff < best_fp_diff:
                best_threshold = mid
                best_fp_diff = fp_diff

            # Binary search adjustment
            if fp_rate > target_fp_rate:
                low = mid  # Increase threshold to reduce FP
            else:
                high = mid  # Decrease threshold

        # Run final simulation with best threshold
        final_simulation = cls.simulate_threshold_impact(
            baseline_profile,
            best_threshold,
            simulation_days
        )

        final_simulation['optimization_method'] = 'binary_search'
        final_simulation['target_fp_rate'] = target_fp_rate
        final_simulation['optimal_threshold'] = best_threshold

        return final_simulation
```

**Lines**: ~145 (within Rule #7 limit)

---

### Component 3: Django Admin Extensions

**File**: `apps/noc/admin.py` (MODIFY - enhance existing)

**Enhancement**: Custom admin for BaselineProfile with threshold management

**Implementation**:
```python
from django.contrib import admin
from django.utils.html import format_html
from apps.noc.security_intelligence.models import BaselineProfile
from apps.noc.security_intelligence.services.threshold_simulator import ThresholdSimulatorService


@admin.register(BaselineProfile)
class BaselineProfileAdmin(admin.ModelAdmin):
    """
    Enhanced admin for BaselineProfile with threshold calibration.

    Features:
    - Inline threshold editing with validation
    - Visual z-score distribution chart
    - Impact simulation before apply
    - Batch threshold updates
    - Audit trail integration
    """

    list_display = [
        'profile_name',
        'metric_type',
        'threshold_display',
        'false_positive_rate_display',
        'is_stable',
        'last_updated',
        'simulate_action'
    ]

    list_filter = ['metric_type', 'is_stable', 'site']

    search_fields = ['site__buname', 'metric_type']

    fields = [
        'site',
        'metric_type',
        'hour_of_week',
        'mean',
        'std_dev',
        'sample_count',
        'dynamic_threshold',  # Editable
        'false_positive_rate',
        'is_stable',
        'threshold_visualization',  # Custom widget
        'impact_simulation',  # Custom widget
    ]

    readonly_fields = [
        'mean',
        'std_dev',
        'sample_count',
        'false_positive_rate',
        'is_stable',
        'threshold_visualization',
        'impact_simulation'
    ]

    def threshold_display(self, obj):
        """Display threshold with color coding."""
        threshold = obj.dynamic_threshold

        if threshold < 2.0:
            color = 'red'  # Very sensitive
        elif threshold < 2.5:
            color = 'orange'  # Sensitive
        elif threshold <= 3.5:
            color = 'green'  # Optimal
        else:
            color = 'blue'  # Conservative

        return format_html(
            '<span style="color: {}; font-weight: bold;">{:.2f}</span>',
            color,
            threshold
        )
    threshold_display.short_description = 'Z-Score Threshold'

    def false_positive_rate_display(self, obj):
        """Display FP rate with warning if high."""
        fp_rate = obj.false_positive_rate

        if fp_rate > 0.30:
            color = 'red'
        elif fp_rate > 0.20:
            color = 'orange'
        else:
            color = 'green'

        return format_html(
            '<span style="color: {};">{:.1%}</span>',
            color,
            fp_rate
        )
    false_positive_rate_display.short_description = 'FP Rate (30d)'

    def threshold_visualization(self, obj):
        """Render z-score distribution chart (Chart.js)."""
        # Return HTML with Chart.js visualization
        # Shows distribution of z-scores with current threshold line
        return format_html(
            '<canvas id="threshold-chart-{}" width="400" height="200"></canvas>'
            '<script>'
            '/* Chart.js code to render distribution + threshold */'
            '</script>',
            obj.id
        )
    threshold_visualization.short_description = 'Z-Score Distribution'

    def impact_simulation(self, obj):
        """Render impact simulation widget."""
        # Interactive slider + simulation results
        return format_html(
            '<div class="threshold-simulator" data-profile-id="{}">'
            '<input type="range" min="1.5" max="5.0" step="0.1" value="{}" />'
            '<div id="simulation-results-{}"></div>'
            '</div>',
            obj.id,
            obj.dynamic_threshold,
            obj.id
        )
    impact_simulation.short_description = 'Impact Simulation'

    def simulate_action(self, obj):
        """Action button to open simulation modal."""
        return format_html(
            '<a class="button" href="/admin/noc/baseline/{}/simulate/">Simulate</a>',
            obj.id
        )
    simulate_action.short_description = 'Actions'

    def save_model(self, request, obj, form, change):
        """Override save to create audit log when threshold changes."""
        from apps.noc.security_intelligence.models import ThresholdAuditLog

        if change and 'dynamic_threshold' in form.changed_data:
            # Get old value
            old_obj = BaselineProfile.objects.get(pk=obj.pk)
            old_threshold = old_obj.dynamic_threshold
            new_threshold = obj.dynamic_threshold

            # Save model first
            super().save_model(request, obj, form, change)

            # Create audit log
            ThresholdAuditLog.objects.create(
                tenant=obj.site.tenant if obj.site else None,
                baseline_profile=obj,
                threshold_type='dynamic_threshold',
                old_value=old_threshold,
                new_value=new_threshold,
                delta=new_threshold - old_threshold,
                changed_by=request.user,
                change_reason=request.POST.get('change_reason', 'Manual adjustment via admin')
            )

            logger.info(
                f"Threshold changed for {obj}: {old_threshold:.2f} ‚Üí {new_threshold:.2f} "
                f"by {request.user.peoplename}"
            )
        else:
            super().save_model(request, obj, form, change)
```

**Lines**: ~140 (within Rule #7 limit)

---

### Component 4: API Endpoints

**File**: `apps/api/v2/views/threshold_views.py` (NEW)

**Endpoints** (4):

#### 1. List Thresholds
```python
GET /api/v2/noc/thresholds/
    ?site_id=123
    &metric_type=phone_events_count
    &is_stable=true

Response:
{
    "count": 50,
    "results": [
        {
            "id": 1,
            "site_name": "Site A",
            "metric_type": "phone_events_count",
            "hour_of_week": 10,
            "dynamic_threshold": 3.2,
            "false_positive_rate": 0.15,
            "is_stable": true,
            "sample_count": 150,
            "last_changed": "2025-11-01T10:30:00Z",
            "last_changed_by": "admin"
        },
        ...
    ]
}
```

#### 2. Update Threshold
```python
PATCH /api/v2/noc/thresholds/{id}/

Request:
{
    "dynamic_threshold": 2.8,
    "change_reason": "Reducing false positives for night shift"
}

Response:
{
    "id": 1,
    "dynamic_threshold": 2.8,
    "audit_log_id": 456,
    "simulation": {
        "projected_alerts": 25,
        "projected_fp_rate": 0.08,
        "recommendation": "Good balance achieved"
    }
}
```

#### 3. Simulate Threshold
```python
POST /api/v2/noc/thresholds/simulate/

Request:
{
    "baseline_profile_id": 1,
    "candidate_threshold": 2.5,
    "simulation_days": 30
}

Response:
{
    "candidate_threshold": 2.5,
    "current_threshold": 3.2,
    "simulation_results": {
        "alert_count": 42,
        "false_positive_rate": 0.12,
        "true_positive_rate": 0.88,
        "precision": 0.76,
        "recommendation": "Good balance, lower FP rate than current"
    },
    "comparison": {
        "alert_count_change": +12,
        "fp_rate_change": -0.03
    }
}
```

#### 4. Reset to Auto-Calculated
```python
POST /api/v2/noc/thresholds/{id}/reset/

Request:
{
    "reason": "Reset to auto-calculated threshold after false positive spike"
}

Response:
{
    "id": 1,
    "old_threshold": 2.5,
    "new_threshold": 3.2,  # Auto-calculated based on FP rate + sample count
    "reset_method": "auto_calculation",
    "audit_log_id": 457
}
```

**Implementation** (~180 lines total):
```python
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework.permissions import IsAuthenticated, IsAdminUser
from rest_framework import status
from django.shortcuts import get_object_or_404

from apps.noc.security_intelligence.models import BaselineProfile
from apps.noc.security_intelligence.services.threshold_simulator import ThresholdSimulatorService
from apps.noc.security_intelligence.serializers import (
    BaselineProfileSerializer,
    ThresholdSimulationSerializer
)


class ThresholdListView(APIView):
    """GET /api/v2/noc/thresholds/"""
    permission_classes = [IsAuthenticated]

    def get(self, request):
        # Filter, serialize, paginate
        ...

class ThresholdUpdateView(APIView):
    """PATCH /api/v2/noc/thresholds/{id}/"""
    permission_classes = [IsAdminUser]  # Admin only

    def patch(self, request, pk):
        # Validate, simulate, update, audit
        ...

class ThresholdSimulateView(APIView):
    """POST /api/v2/noc/thresholds/simulate/"""
    permission_classes = [IsAuthenticated]

    def post(self, request):
        # Run simulation, return results
        ...

class ThresholdResetView(APIView):
    """POST /api/v2/noc/thresholds/{id}/reset/"""
    permission_classes = [IsAdminUser]

    def post(self, request, pk):
        # Reset to auto-calculated, audit
        ...
```

---

## Implementation Timeline

### Week 1: Foundation (Days 1-5)

**Day 1 (Monday): ThresholdAuditLog Model**
- [ ] Create `apps/noc/security_intelligence/models/threshold_audit_log.py`
- [ ] Create migration
- [ ] Update `apps/noc/security_intelligence/models/__init__.py`
- [ ] Unit tests (10 tests)

**Day 2 (Tuesday): ThresholdSimulatorService**
- [ ] Create `apps/noc/security_intelligence/services/threshold_simulator.py`
- [ ] Implement `simulate_threshold_impact()`
- [ ] Implement `find_optimal_threshold()`
- [ ] Unit tests (12 tests: simulation accuracy, edge cases)

**Day 3 (Wednesday): Django Admin Enhancement**
- [ ] Enhance `apps/noc/admin.py` BaselineProfileAdmin
- [ ] Add threshold visualization fields
- [ ] Add save_model override for audit
- [ ] Create admin templates (Chart.js)

**Day 4 (Thursday): API Endpoints (Part 1)**
- [ ] Create `apps/api/v2/views/threshold_views.py`
- [ ] Implement ThresholdListView + ThresholdUpdateView
- [ ] Create serializers
- [ ] Unit tests (8 tests)

**Day 5 (Friday): API Endpoints (Part 2)**
- [ ] Implement ThresholdSimulateView + ThresholdResetView
- [ ] Update `apps/api/v2/urls.py`
- [ ] Integration tests (6 tests)
- [ ] Week 1 validation

---

### Week 2: Polish & Deploy (Days 6-10)

**Day 6 (Monday): Frontend UI** (if React/Vue exists)
- [ ] Create threshold management component
- [ ] Interactive slider with live simulation
- [ ] Chart.js integration (z-score distribution)
- [ ] Audit trail table view

**Day 7 (Tuesday): Batch Operations**
- [ ] Batch threshold update endpoint
- [ ] Site-wide threshold reset
- [ ] Bulk audit log export (CSV)

**Day 8 (Wednesday): Documentation**
- [ ] Create `docs/operations/THRESHOLD_CALIBRATION_GUIDE.md`
- [ ] Update `CLAUDE.md` with Phase 3 features
- [ ] API documentation (OpenAPI schema)
- [ ] Screenshots/diagrams

**Day 9 (Thursday): Testing & Validation**
- [ ] Full test suite (50+ tests total)
- [ ] Load test (simulate 1000 thresholds)
- [ ] Integration test (admin + API + simulation)
- [ ] Security review (permission enforcement)

**Day 10 (Friday): Deployment**
- [ ] Create `PHASE3_IMPLEMENTATION_REPORT.md`
- [ ] Staging deployment
- [ ] Smoke test
- [ ] Production deployment plan

---

## Success Criteria

### Technical
- ‚úÖ Threshold simulation accurate (within 5% of actual)
- ‚úÖ Audit log captures all changes
- ‚úÖ API response time < 200ms (95th percentile)
- ‚úÖ Rollback works in < 1 minute
- ‚úÖ 95%+ test coverage

### Operational
- ‚úÖ Operators can adjust thresholds independently
- ‚úÖ Threshold adjustment time < 5 minutes
- ‚úÖ Impact preview before applying changes
- ‚úÖ Complete audit trail for compliance

### Business
- ‚úÖ 98% reduction in threshold adjustment time
- ‚úÖ Zero code deployments for threshold changes
- ‚úÖ Improved operator satisfaction (self-service)

---

## Estimated Effort

**Total**: 80 hours (2 weeks, 1 FTE)

| Component | Hours |
|-----------|-------|
| ThresholdAuditLog Model | 8h |
| ThresholdSimulatorService | 16h |
| Django Admin Extensions | 12h |
| API Endpoints | 16h |
| Frontend UI (if needed) | 16h |
| Testing | 20h |
| Documentation | 8h |

---

**Plan Status**: ‚úÖ **READY FOR IMPLEMENTATION**

**Next**: Create feature branch and begin Day 1 tasks

