"""
Phase 1 Performance Gate: Verify ontology decorators have zero runtime cost.

PASS CRITERIA:
- Memory delta < 5MB compared to baseline
- Latency delta < 10ms compared to baseline
- 15+ services registered in ontology (help, helpdesk domains)

FAIL ACTION: Remove decorators, investigate

NOTE: These tests compare against the pre-decorator baseline to verify
      that adding ontology decorators has negligible performance impact.
"""

import json
import os
import subprocess
import sys
import pytest


def load_baseline():
    """Load original baseline."""
    baseline_path = os.path.join(
        os.path.dirname(__file__),
        '../../performance_baseline.json'
    )
    with open(baseline_path) as f:
        return json.load(f)


def run_baseline_script():
    """
    Run baseline script in a separate process to avoid Django settings conflicts.

    pytest uses test settings (limited INSTALLED_APPS) while the baseline
    script needs full settings. Running in separate process solves this.
    """
    script_path = os.path.join(
        os.path.dirname(__file__),
        '../../scripts/performance/baseline_help_modules.py'
    )

    # Run baseline script as subprocess
    result = subprocess.run(
        [sys.executable, script_path],
        capture_output=True,
        text=True,
        timeout=180
    )

    if result.returncode != 0:
        print(f"Baseline script failed:\n{result.stderr}")
        raise RuntimeError(f"Baseline script failed with exit code {result.returncode}")

    # Load the newly generated baseline
    return load_baseline()


def test_memory_impact():
    """
    Verify memory impact of ontology decorators < 5MB.

    NOTE: This test requires Django to be properly configured with environment
    variables. If baseline regeneration fails, test is skipped with warning.
    """
    # Load original baseline (before decorators)
    baseline_path = os.path.join(
        os.path.dirname(__file__),
        '../../performance_baseline.json'
    )

    # Backup original baseline
    baseline_backup_path = baseline_path + '.original'
    if not os.path.exists(baseline_backup_path):
        import shutil
        shutil.copy(baseline_path, baseline_backup_path)

    with open(baseline_backup_path) as f:
        baseline = json.load(f)

    # Try to run current baseline
    try:
        current = run_baseline_script()
    except (RuntimeError, subprocess.TimeoutExpired) as e:
        pytest.skip(f"Baseline script failed (Django config issue): {e}")
        return

    baseline_memory = baseline['memory']['delta_mb']
    current_memory = current['memory']['delta_mb']

    delta = abs(current_memory - baseline_memory)

    print(f"\n  Baseline memory delta: {baseline_memory:.2f}MB")
    print(f"  Current memory delta: {current_memory:.2f}MB")
    print(f"  Absolute delta: {delta:.2f}MB")

    assert delta < 5.0, f"Memory impact {delta:.2f}MB exceeds 5MB threshold"


def test_helpbot_latency_impact():
    """Verify HelpBot latency delta < 10ms."""
    # Load original baseline (before decorators)
    baseline_path = os.path.join(
        os.path.dirname(__file__),
        '../../performance_baseline.json.original'
    )

    if not os.path.exists(baseline_path):
        pytest.skip("Original baseline not found - run test_memory_impact first")

    with open(baseline_path) as f:
        baseline = json.load(f)

    # Current baseline already generated by previous test
    current = load_baseline()

    baseline_p95 = baseline['mock_benchmarks']['helpbot']['p95']
    current_p95 = current['mock_benchmarks']['helpbot']['p95']

    delta = abs(current_p95 - baseline_p95)

    print(f"\n  Baseline HelpBot P95: {baseline_p95:.2f}ms")
    print(f"  Current HelpBot P95: {current_p95:.2f}ms")
    print(f"  Absolute delta: {delta:.2f}ms")

    assert delta < 10.0, f"HelpBot latency delta {delta:.2f}ms exceeds 10ms threshold"


def test_help_center_latency_impact():
    """Verify help_center latency delta < 10ms."""
    # Load original baseline (before decorators)
    baseline_path = os.path.join(
        os.path.dirname(__file__),
        '../../performance_baseline.json.original'
    )

    if not os.path.exists(baseline_path):
        pytest.skip("Original baseline not found - run test_memory_impact first")

    with open(baseline_path) as f:
        baseline = json.load(f)

    # Current baseline already generated by previous test
    current = load_baseline()

    baseline_p95 = baseline['mock_benchmarks']['help_center']['p95']
    current_p95 = current['mock_benchmarks']['help_center']['p95']

    delta = abs(current_p95 - baseline_p95)

    print(f"\n  Baseline help_center P95: {baseline_p95:.2f}ms")
    print(f"  Current help_center P95: {current_p95:.2f}ms")
    print(f"  Absolute delta: {delta:.2f}ms")

    assert delta < 10.0, f"help_center latency delta {delta:.2f}ms exceeds 10ms threshold"


def test_ontology_decorator_presence():
    """
    Verify 15+ services have @ontology decorators.

    NOTE: This test verifies decorator PRESENCE, not runtime registration.
    Runtime registration requires full Django initialization which conflicts
    with pytest's test settings. In production, app.ready() methods will
    trigger registration automatically.
    """
    import ast
    import os

    # Define service files to check
    service_files = [
        # help_center (5 services)
        'apps/help_center/services/ai_assistant_service.py',
        'apps/help_center/services/search_service.py',
        'apps/help_center/services/knowledge_service.py',
        'apps/help_center/services/analytics_service.py',
        'apps/help_center/services/ticket_integration_service.py',
        # helpbot (5 services)
        'apps/helpbot/services/conversation_service.py',
        'apps/helpbot/services/knowledge_service.py',
        'apps/helpbot/services/parlant_agent_service.py',
        'apps/helpbot/services/context_service.py',
        'apps/helpbot/services/ticket_intent_classifier.py',
        # y_helpdesk (6 services)
        'apps/y_helpdesk/services/ai_summarizer.py',
        'apps/y_helpdesk/services/kb_suggester.py',
        'apps/y_helpdesk/services/duplicate_detector.py',
        'apps/y_helpdesk/services/sla_calculator.py',
        'apps/y_helpdesk/services/reply_macros.py',
        'apps/y_helpdesk/services/playbook_suggester.py',
    ]

    project_root = os.path.join(os.path.dirname(__file__), '../..')
    services_with_decorators = []
    services_without_decorators = []

    print(f"\n  Checking {len(service_files)} service files for @ontology decorators...")

    for service_file in service_files:
        file_path = os.path.join(project_root, service_file)

        if not os.path.exists(file_path):
            print(f"  ⚠️  File not found: {service_file}")
            services_without_decorators.append(service_file)
            continue

        with open(file_path, 'r') as f:
            content = f.read()

        # Check for @ontology decorator
        has_decorator = '@ontology(' in content or '@ontology\n' in content

        if has_decorator:
            # Also check for domain='help' or domain='helpdesk'
            has_help_domain = 'domain="help"' in content or "domain='help'" in content
            has_helpdesk_domain = 'domain="helpdesk"' in content or "domain='helpdesk'" in content

            if has_help_domain or has_helpdesk_domain:
                domain = 'help' if has_help_domain else 'helpdesk'
                services_with_decorators.append((service_file, domain))
                print(f"  ✅ {os.path.basename(service_file)} - domain={domain}")
            else:
                print(f"  ⚠️  {os.path.basename(service_file)} - has @ontology but wrong domain")
                services_without_decorators.append(service_file)
        else:
            print(f"  ❌ {os.path.basename(service_file)} - missing @ontology decorator")
            services_without_decorators.append(service_file)

    print(f"\n  Services with @ontology decorators: {len(services_with_decorators)}/16")
    print(f"  Services missing decorators: {len(services_without_decorators)}")

    if services_without_decorators:
        print(f"\n  Missing decorators in:")
        for service in services_without_decorators:
            print(f"    - {service}")

    # Expect at least 15 services (we actually have 16: 5 + 5 + 6)
    assert len(services_with_decorators) >= 15, \
        f"Expected 15+ services with @ontology decorators, found {len(services_with_decorators)}"
